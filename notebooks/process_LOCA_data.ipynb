{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import io\n",
    "import os\n",
    "os.chdir(\"/Users/canyonfoot/Documents/python_proj/nwf-process-geodata\")\n",
    "from src.common import *\n",
    "from rasterio.mask import mask\n",
    "from rasterio.io import MemoryFile\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = get_s3_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_LOCA_csv_from_s3_tar_gz(s3, bucket_name, tar_gz_key, csv_filename, skiprows = 1):\n",
    "    obj = s3.get_object(Bucket=bucket_name, Key=tar_gz_key)\n",
    "    tar_gz_stream = io.BytesIO(obj['Body'].read())\n",
    "    \n",
    "    with tarfile.open(fileobj=tar_gz_stream, mode='r:gz') as tar:\n",
    "        csv_file = tar.extractfile(csv_filename)\n",
    "        df = pd.read_csv(csv_file, skiprows=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def _preprocess_LOCA(df):\n",
    "    value_col = \"combined\"\n",
    "    df = df.replace(-999.0, np.NaN)\n",
    "    df[\"combined\"] = df[\"1976-2005\"] + df[\"2036-2065.1\"]\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.LON, df.LAT), crs='EPSG:4326')[[value_col, \"geometry\"]]\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def _create_raster(gdf, full_path, value_col = 'combined', x_res = 0.05, y_res = 0.05):\n",
    "    x_min, y_min, x_max, y_max = gdf.total_bounds\n",
    "\n",
    "    # Create a transform\n",
    "    transform = from_origin(x_min, y_max, x_res, y_res)\n",
    "\n",
    "    # Prepare grid coordinates (correcting for typical meshgrid usage in scientific plotting)\n",
    "    grid_y, grid_x = np.mgrid[y_max:y_min:-y_res, x_min:x_max:x_res]  # Notice the reversed order and negative step for y\n",
    "\n",
    "    # Perform interpolation\n",
    "    raster = griddata(\n",
    "        points=(gdf.geometry.x, gdf.geometry.y),\n",
    "        values=gdf[value_col], \n",
    "        xi=(grid_x, grid_y),\n",
    "        method='nearest'\n",
    "    )\n",
    "\n",
    "    # Write the raster\n",
    "    with rasterio.open(\n",
    "        full_path, \n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=raster.shape[0],\n",
    "        width=raster.shape[1],\n",
    "        count=1,\n",
    "        dtype=str(raster.dtype),\n",
    "        crs='+proj=latlong',\n",
    "        transform=transform,\n",
    "    ) as dst:\n",
    "        dst.write(raster, 1)\n",
    "    \n",
    "def _trim_raster_to_wy(raster_path, trim_path):\n",
    "    # Read the raster file\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        wyoming_gdf = gpd.read_file(\"wyoming.geojson\")\n",
    "        \n",
    "        # Mask the raster with the polygon\n",
    "        out_image, out_transform = mask(src, wyoming_gdf.geometry, crop=True)\n",
    "        out_image[out_image == 0] = np.nan\n",
    "\n",
    "        # Update metadata for the cropped raster\n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": out_image.shape[1],\n",
    "            \"width\": out_image.shape[2],\n",
    "            \"transform\": out_transform,\n",
    "            \"nodata\" : np.nan\n",
    "        })\n",
    "        \n",
    "    with rasterio.open(trim_path, 'w', **out_meta) as dest:\n",
    "        dest.write(out_image)\n",
    "\n",
    "def main_process_LOCA(s3, BUCKET_NAME, tar_gz_key, csv_filename, full_path, trimmed_path):\n",
    "    df = _read_LOCA_csv_from_s3_tar_gz(s3, BUCKET_NAME, tar_gz_key, csv_filename, skiprows=1)\n",
    "    gdf = _preprocess_LOCA(df)\n",
    "    _create_raster(gdf,full_path)\n",
    "    _trim_raster_to_wy(full_path, trimmed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchKey",
     "evalue": "An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchKey\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m full_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_raster.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m trimmed_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrimmed_raster.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mmain_process_LOCA\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBUCKET_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtar_gz_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrimmed_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 74\u001b[0m, in \u001b[0;36mmain_process_LOCA\u001b[0;34m(s3, BUCKET_NAME, tar_gz_key, csv_filename, full_path, trimmed_path)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain_process_LOCA\u001b[39m(s3, BUCKET_NAME, tar_gz_key, csv_filename, full_path, trimmed_path):\n\u001b[0;32m---> 74\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43m_read_LOCA_csv_from_s3_tar_gz\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBUCKET_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtar_gz_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     gdf \u001b[38;5;241m=\u001b[39m _preprocess_LOCA(df)\n\u001b[1;32m     76\u001b[0m     _create_raster(gdf,full_path)\n",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m, in \u001b[0;36m_read_LOCA_csv_from_s3_tar_gz\u001b[0;34m(s3, bucket_name, tar_gz_key, csv_filename, skiprows)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_LOCA_csv_from_s3_tar_gz\u001b[39m(s3, bucket_name, tar_gz_key, csv_filename, skiprows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43ms3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtar_gz_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     tar_gz_stream \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mopen(fileobj\u001b[38;5;241m=\u001b[39mtar_gz_stream, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr:gz\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tar:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/nwf-process-geodata-YVXeQpfw-py3.9/lib/python3.9/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/nwf-process-geodata-YVXeQpfw-py3.9/lib/python3.9/site-packages/botocore/client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mNoSuchKey\u001b[0m: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist."
     ]
    }
   ],
   "source": [
    "bucket_name = BUCKET_NAME\n",
    "tar_gz_key = 'data/raw/climate_change_indicators/extreme_heat/loca_extreme_temperature_forecast.tar.gz'\n",
    "full_path = \"output_raster.tif\"\n",
    "trimmed_path = \"trimmed_raster.tif\"\n",
    "\n",
    "df = main_process_LOCA(s3, BUCKET_NAME, tar_gz_key, csv_filename, full_path, trimmed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.read_file(\"/Users/canyonfoot/Downloads/Data-1/FPA_FOD_20221014.gdb/a0000000c.gdbtable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nwf-process-geodata-YVXeQpfw-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
